{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eacaa41",
   "metadata": {},
   "source": [
    "# Sentiment analysis using Text Blob"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8070484d",
   "metadata": {},
   "source": [
    "Text Blob is a python for Natural Language Processing which takes text as an input and can return polarity and subjectivity as outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a04857",
   "metadata": {},
   "source": [
    "Polarity: determines the sentiment of the text which value lie in [-1, 1] where -1 denotes a highly negative sentiment\n",
    "and 1 denotes a highly positive sentiment.\n",
    "Subjectivity: this relates whether the text is factual or personal opinion. This value lies in between [0,1] where 0 represents the factual information and 1 represents the personal opinion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45e03c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: joblib in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86be5401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (22.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54fd20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa6a941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity of Text 1 is 0.8\n",
      "Polarity of Text 2 is 0.0\n",
      "Subjectivity of Text 1 is 1.0\n",
      "Subjectivity of Text 2 is 1.0\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"I am so happy today.\"\n",
    "text_2 = \"I don't like the food of that restaurant\"\n",
    "\n",
    "#Determining the polarity of the abovementioned texts\n",
    "p_1 = TextBlob(text_1).sentiment.polarity\n",
    "p_2 = TextBlob(text_2).sentiment.polarity\n",
    "\n",
    "#Exploring the Subjectivity\n",
    "s_1 = TextBlob(text_1).sentiment.subjectivity\n",
    "s_2 = TextBlob(text_2).sentiment.subjectivity\n",
    "\n",
    "print(\"Polarity of Text 1 is\", p_1)\n",
    "print(\"Polarity of Text 2 is\", p_2)\n",
    "print(\"Subjectivity of Text 1 is\", s_1)\n",
    "print(\"Subjectivity of Text 2 is\", s_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc9453",
   "metadata": {},
   "source": [
    "From the above result, we can extract the information that the first sentence showing the positivity and hence the value is approaching towards 1 where as the second sentense is neutral in case of polarity (i.e., not much negativity and positivity). Talking about sensitivity, both the sentences show personal opinion and not factual information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb029aad",
   "metadata": {},
   "source": [
    "# Sentiment analysis using VADER\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c8da2",
   "metadata": {},
   "source": [
    "VADER (Valence aware Dictionary and sEntiment Reasoner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6be79",
   "metadata": {},
   "source": [
    "First install the required library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1159a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from vaderSentiment) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lochanbasyal/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a47d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bceb9721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of the text 1: {'neg': 0.0, 'neu': 0.561, 'pos': 0.439, 'compound': 0.7397}\n",
      "Sentiment of the text 2: {'neg': 0.487, 'neu': 0.513, 'pos': 0.0, 'compound': -0.5849}\n"
     ]
    }
   ],
   "source": [
    "sentiment = SentimentIntensityAnalyzer()\n",
    "text_1 = \"This book was really amazing and worth it to read.\"\n",
    "text_2 = \"That burger was really bad.\"\n",
    "\n",
    "sent_1 = sentiment.polarity_scores(text_1)\n",
    "sent_2 = sentiment.polarity_scores(text_2)\n",
    "\n",
    "print(\"Sentiment of the text 1:\", sent_1)\n",
    "print(\"Sentiment of the text 2:\", sent_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab21ee4",
   "metadata": {},
   "source": [
    "The above result shows the dictionary of the sentiment scores from the abovementioned texts. From the result, it can be said that text 1 is positive and text 2 is negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b82be",
   "metadata": {},
   "source": [
    "# Bag of Words Vectorization-Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0a152",
   "metadata": {},
   "source": [
    "For this technique, we need to pre-process the text of training data, creating a bag of words and train a suitable classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5210eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "0     The GeoSolutions technology will leverage Bene...  positive\n",
       "1     $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2     For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3     According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4     The Swedish buyout firm has sold its remaining...   neutral\n",
       "...                                                 ...       ...\n",
       "5837  RISING costs have forced packaging producer Hu...  negative\n",
       "5838  Nordic Walking was first used as a summer trai...   neutral\n",
       "5839  According shipping company Viking Line , the E...   neutral\n",
       "5840  In the building and home improvement trade , s...   neutral\n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...  positive\n",
       "\n",
       "[5842 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the datasets\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "#Visualize the data\n",
    "data.head()\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e1ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing and bag of word vectorization using Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ae4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07102968",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')  #Pre-processing with tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f224fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words ='english', ngram_range = (1,1), tokenizer = token.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "530b89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts = cv.fit_transform(data['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "361a84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data for training and testing set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_text = train_test_split(text_counts, data['Sentiment'], test_size = 0.3, random_state =5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f538329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a952d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.6782658300057045\n"
     ]
    }
   ],
   "source": [
    "#calculating the accuracy score of the model\n",
    "from sklearn import metrics\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_text)\n",
    "print(\"Accuracy Score:\", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549d435",
   "metadata": {},
   "source": [
    "The data used in this model has been obtained from kaggle. Link: https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis?resource=download&select=data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25533a01",
   "metadata": {},
   "source": [
    "# LSTM Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01286f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "#import nltk\n",
    "#import pandas as pd\n",
    "#from textblob import Word\n",
    "#from nltk.corpus import stopwords\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#from keras.models import Sequential\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "#from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d92ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
